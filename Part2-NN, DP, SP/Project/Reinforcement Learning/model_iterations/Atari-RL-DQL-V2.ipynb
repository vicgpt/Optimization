{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36990aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\lib\\site-packages\\ale_py\\roms\\__init__.py:94: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
      "  _RESOLVED_ROMS = _resolve_roms()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99886234",
   "metadata": {},
   "source": [
    "## Pong\n",
    "\n",
    "Deep Q learning with memory buffer - varying probs to oversample minority (cases when you win), action every 4 frame, and linear annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e714c451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# function to convert each image into lesser size\n",
    "def prepro(I):\n",
    "    # preprocess each frame for learning\n",
    "    # save some memory and computation\n",
    "    # pre-process the image from a 210x160x3 uint8 frame into an (80x80) float array \n",
    "    I = I[35:195,:,:].copy() # crop the top of the image...score image doesn't matter for how to play\n",
    "    I = I[::2,::2,0].copy()\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return np.array(I.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9035db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(height,width,channels):\n",
    "    # we cannot simply have 3 output nodes because we want to put a weight on each node's impact to the objective\n",
    "    # that is different for each data point.  the only way to achieve this is to have 3 output layers, each having 1 node\n",
    "    # the effect is the same, just the way TF/keras handles weights is different\n",
    "    imp = Input(shape=(height,width,channels))\n",
    "    mid = Conv2D(32,(8,8),strides=4,activation='relu')(imp)\n",
    "    mid = Conv2D(64,(4,4),strides=2,activation='relu')(mid)\n",
    "    mid = Conv2D(64,(3,3),strides=1,activation='relu')(mid)\n",
    "    mid = Flatten()(mid)\n",
    "    mid = Dense(512,activation='relu')(mid)\n",
    "    mid = Dense(256,activation='relu')(mid)\n",
    "    out0 = Dense(1,activation='linear',name='out0')(mid)\n",
    "    out1 = Dense(1,activation='linear',name='out1')(mid)\n",
    "    out2 = Dense(1,activation='linear',name='out2')(mid)\n",
    "    model = Model(imp,[out0,out1,out2]) \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=25e-6),loss=tf.keras.losses.Huber())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca19ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 80, 80, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 19, 19, 32)   8224        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 8, 64)     32832       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 6, 64)     36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2304)         0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          1180160     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          131328      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " out0 (Dense)                   (None, 1)            257         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " out1 (Dense)                   (None, 1)            257         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " out2 (Dense)                   (None, 1)            257         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,390,243\n",
      "Trainable params: 1,390,243\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frames_to_net = 4              # how many previous frames will we feed the NN\n",
    "possible_actions = [0,2,3]\n",
    "mod = create_model(80,80,frames_to_net)\n",
    "mod.call = tf.function(mod.call,experimental_relax_shapes=True)\n",
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bc61e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play1game(model,ep):\n",
    "    env0 = gym.make(\"Pong-v0\")\n",
    "    pix = env0.reset()\n",
    "    pix = prepro(pix)\n",
    "    frames_this_game = 0\n",
    "    feed = np.zeros((1,80,80,frames_to_net))\n",
    "    feed[0,:,:,0] = pix.copy() # 0 is the most recent frame t; 1 the previous one t+1 and so one\n",
    "    \n",
    "    frame_array = []\n",
    "    action_array = []\n",
    "    reward_array = []\n",
    "    \n",
    "    score = 0\n",
    "    feed_reward = 0\n",
    "    action = np.random.choice(3)\n",
    "    action0 = possible_actions[action]\n",
    "    done = False\n",
    "    while not done:\n",
    "        # updating action every 4 frames\n",
    "        # but taking that action for the 4 frames just not using the prediction for action\n",
    "        if (frames_this_game % 4 == 0) & (frames_this_game != 0):\n",
    "            \n",
    "            frame_array.append(feed)\n",
    "            action_array.append(action)\n",
    "            reward_array.append(feed_reward)\n",
    "            \n",
    "            if np.random.random() < ep:\n",
    "                action = np.random.choice(3)\n",
    "            else:\n",
    "                vf = mod(feed,training=False)\n",
    "                vf = [vf[0][0,0].numpy(),vf[1][0,0].numpy(),vf[2][0,0].numpy()]\n",
    "                action = np.argmax(vf)\n",
    "                \n",
    "            feed_reward = 0\n",
    "            \n",
    "        action0 = possible_actions[action]\n",
    "        pix_new, reward, done, info = env0.step(action0)\n",
    "\n",
    "        pix = prepro(pix_new)\n",
    "        frames_this_game += 1\n",
    "\n",
    "        for f in range(1,frames_to_net):\n",
    "            feed[0,:,:,frames_to_net-f] = feed[0,:,:,frames_to_net-f-1].copy()\n",
    "        feed[0,:,:,0] = pix.copy()\n",
    "        score += reward\n",
    "    return frame_array, action_array, reward_array, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "719f8cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36904761904761907 0.4087301587301587 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# testing the likelihood of taking each action without any training\n",
    "frames, actions, rewards, score = play1game(mod,0.5)\n",
    "print(np.mean(np.array(actions)==0),np.mean(np.array(actions)==1),np.mean(np.array(actions)==2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8723a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discounting factor\n",
    "delt = 0.99\n",
    "\n",
    "# setting up variable for memory buffer\n",
    "ngames = 1000\n",
    "# ngames = 100\n",
    "nbatch = 64\n",
    "buffn = 20000\n",
    "warmupgames = 50\n",
    "len_buff = 0\n",
    "buffer = {'frames':[],'actions':[], 'rewards':[]}\n",
    "\n",
    "# eps vector for each gradient for linear annealing\n",
    "epsvec = np.linspace(0.5,0.05,250)\n",
    "output_qdl = {'game':[-1]*ngames, 'score':[-100]*ngames, 'time':[-1]*ngames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c36f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number  0 [-21.0, 0.5, 2.203951358795166]\n",
      "Game number  10 [-21.0, 0.4819277108433735, 1.9441626071929932]\n",
      "Game number  20 [-21.0, 0.463855421686747, 1.8434054851531982]\n",
      "Game number  30 [-21.0, 0.4457831325301205, 2.075533628463745]\n",
      "Game number  40 [-21.0, 0.42771084337349397, 2.4606990814208984]\n",
      "Game number  50 [-21.0, 0.40963855421686746, 2.5529916286468506]\n",
      "Game number  60 [-21.0, 0.39156626506024095, 2.0724635124206543]\n",
      "Game number  70 [-21.0, 0.37349397590361444, 1.8907365798950195]\n",
      "Game number  80 [-21.0, 0.35542168674698793, 2.1993179321289062]\n",
      "Game number  90 [-21.0, 0.3373493975903614, 1.8546216487884521]\n",
      "Game number  100 [-21.0, 0.3192771084337349, 2.5508949756622314]\n",
      "Game number  110 [-21.0, 0.3012048192771084, 2.0136959552764893]\n",
      "Game number  120 [-20.0, 0.2831325301204819, 2.2816162109375]\n",
      "Game number  130 [-21.0, 0.2650602409638554, 1.8680012226104736]\n",
      "Game number  140 [-21.0, 0.24698795180722893, 2.417581081390381]\n",
      "Game number  150 [-21.0, 0.22891566265060243, 1.8934900760650635]\n",
      "Game number  160 [-21.0, 0.21084337349397592, 1.8229129314422607]\n",
      "Game number  170 [-21.0, 0.1927710843373494, 2.020636796951294]\n",
      "Game number  180 [-21.0, 0.1746987951807229, 2.54070782661438]\n",
      "Game number  190 [-21.0, 0.1566265060240964, 3.0468783378601074]\n",
      "Game number  200 [-21.0, 0.13855421686746988, 2.1523637771606445]\n",
      "Game number  210 [-21.0, 0.12048192771084337, 2.038095712661743]\n",
      "Game number  220 [-21.0, 0.10240963855421686, 2.5221869945526123]\n",
      "Game number  230 [-21.0, 0.08433734939759036, 2.1033990383148193]\n",
      "Game number  240 [-21.0, 0.06626506024096385, 2.234621286392212]\n",
      "Game number  250 [-21.0, 0.05, 2.836991548538208]\n",
      "Game number  260 [-21.0, 0.05, 2.3785388469696045]\n",
      "Game number  270 [-21.0, 0.05, 2.3205630779266357]\n",
      "Game number  280 [-21.0, 0.05, 2.56628155708313]\n",
      "Game number  290 [-21.0, 0.05, 2.1942391395568848]\n",
      "Game number  300 [-21.0, 0.05, 2.7271554470062256]\n",
      "Game number  310 [-21.0, 0.05, 2.725398063659668]\n",
      "Game number  320 [-21.0, 0.05, 2.7740767002105713]\n",
      "Game number  330 [-21.0, 0.05, 2.544677972793579]\n",
      "Game number  340 [-21.0, 0.05, 2.5829849243164062]\n",
      "Game number  350 [-21.0, 0.05, 2.5828335285186768]\n",
      "Game number  360 [-21.0, 0.05, 2.3975162506103516]\n",
      "Game number  370 [-21.0, 0.05, 2.394618034362793]\n",
      "Game number  380 [-21.0, 0.05, 2.8982863426208496]\n",
      "Game number  390 [-21.0, 0.05, 2.583116054534912]\n",
      "Game number  400 [-21.0, 0.05, 2.4389567375183105]\n",
      "Game number  410 [-21.0, 0.05, 2.8164546489715576]\n",
      "Game number  420 [-21.0, 0.05, 2.3972408771514893]\n",
      "Game number  430 [-21.0, 0.05, 2.2840075492858887]\n",
      "Game number  440 [-21.0, 0.05, 2.3512561321258545]\n",
      "Game number  450 [-21.0, 0.05, 2.1067581176757812]\n",
      "Game number  460 [-21.0, 0.05, 2.780149459838867]\n",
      "Game number  470 [-21.0, 0.05, 2.161961793899536]\n",
      "Game number  480 [-21.0, 0.05, 2.3812224864959717]\n",
      "Game number  490 [-21.0, 0.05, 2.61094331741333]\n",
      "Game number  500 [-21.0, 0.05, 2.661403179168701]\n",
      "Game number  510 [-21.0, 0.05, 2.5198793411254883]\n",
      "Game number  520 [-21.0, 0.05, 1.8774142265319824]\n",
      "Game number  530 [-21.0, 0.05, 2.5799777507781982]\n",
      "Game number  540 [-21.0, 0.05, 2.578791379928589]\n",
      "Game number  550 [-21.0, 0.05, 2.618939161300659]\n",
      "Game number  560 [-21.0, 0.05, 1.8991665840148926]\n",
      "Game number  570 [-21.0, 0.05, 2.1538941860198975]\n",
      "Game number  580 [-21.0, 0.05, 2.4862234592437744]\n",
      "Game number  590 [-21.0, 0.05, 2.4368202686309814]\n",
      "Game number  600 [-20.0, 0.05, 2.7106263637542725]\n",
      "Game number  610 [-21.0, 0.05, 1.8463051319122314]\n",
      "Game number  620 [-21.0, 0.05, 1.933464765548706]\n",
      "Game number  630 [-21.0, 0.05, 2.311800718307495]\n",
      "Game number  640 [-21.0, 0.05, 2.1533331871032715]\n",
      "Game number  650 [-21.0, 0.05, 2.662710189819336]\n",
      "Game number  660 [-21.0, 0.05, 1.7466905117034912]\n",
      "Game number  670 [-21.0, 0.05, 2.2321412563323975]\n",
      "Game number  680 [-21.0, 0.05, 2.5882833003997803]\n",
      "Game number  690 [-21.0, 0.05, 2.516948699951172]\n",
      "Game number  700 [-21.0, 0.05, 2.8594954013824463]\n",
      "Game number  710 [-21.0, 0.05, 2.6356165409088135]\n",
      "Game number  720 [-21.0, 0.05, 2.5585594177246094]\n",
      "Game number  730 [-21.0, 0.05, 2.5701868534088135]\n",
      "Game number  740 [-21.0, 0.05, 2.14839506149292]\n",
      "Game number  750 [-21.0, 0.05, 2.1314444541931152]\n",
      "Game number  760 [-21.0, 0.05, 2.500840187072754]\n",
      "Game number  770 [-21.0, 0.05, 1.700483798980713]\n",
      "Game number  780 [-21.0, 0.05, 2.1512184143066406]\n",
      "Game number  790 [-21.0, 0.05, 2.6047205924987793]\n",
      "Game number  800 [-21.0, 0.05, 2.208562135696411]\n",
      "Game number  810 [-21.0, 0.05, 2.3061182498931885]\n",
      "Game number  820 [-21.0, 0.05, 2.727705955505371]\n",
      "Game number  830 [-21.0, 0.05, 2.1015634536743164]\n",
      "Game number  840 [-21.0, 0.05, 3.1308364868164062]\n",
      "Game number  850 [-21.0, 0.05, 2.784262180328369]\n",
      "Game number  860 [-21.0, 0.05, 1.9405858516693115]\n",
      "Game number  870 [-21.0, 0.05, 2.6678061485290527]\n",
      "Game number  880 [-21.0, 0.05, 2.9298195838928223]\n",
      "Game number  890 [-21.0, 0.05, 2.597270965576172]\n",
      "Game number  900 [-21.0, 0.05, 2.68827223777771]\n",
      "Game number  910 [-21.0, 0.05, 2.4204280376434326]\n",
      "Game number  920 [-21.0, 0.05, 2.2732093334198]\n",
      "Game number  930 [-21.0, 0.05, 2.6398887634277344]\n",
      "Game number  940 [-21.0, 0.05, 2.1477460861206055]\n",
      "Game number  950 [-21.0, 0.05, 1.9874932765960693]\n",
      "Game number  960 [-21.0, 0.05, 2.0119802951812744]\n",
      "Game number  970 [-21.0, 0.05, 2.3843183517456055]\n",
      "Game number  980 [-21.0, 0.05, 2.444896936416626]\n",
      "Game number  990 [-21.0, 0.05, 2.5015885829925537]\n",
      "total run time,  40.279053215185805 minutes\n"
     ]
    }
   ],
   "source": [
    "overall_start = time.time()\n",
    "\n",
    "for game in range(ngames):\n",
    "    if game < len(epsvec):\n",
    "        eps = epsvec[game]\n",
    "    else:\n",
    "        eps = epsvec[-1]\n",
    "    \n",
    "    start = time.time()\n",
    "    frames, actions, rewards, score = play1game(mod,eps)\n",
    "    buffer['frames'] += frames.copy()\n",
    "    buffer['actions'] += actions.copy()\n",
    "    buffer['rewards'] += rewards.copy()\n",
    "    len_buff += len(actions)\n",
    "    if len_buff > buffn:\n",
    "        excess = len_buff - buffn\n",
    "        buffer['frames'] = buffer['frames'][excess:].copy()\n",
    "        buffer['actions'] = buffer['actions'][excess:].copy()\n",
    "        buffer['rewards'] = buffer['rewards'][excess:].copy()\n",
    "        len_buff = len(buffer['actions'])\n",
    "    \n",
    "    # rewards = np.array(rewards)\n",
    "    # actions = np.array(actions)\n",
    "    \n",
    "    nframes = len(frames)\n",
    "    current_frames = np.zeros((nframes,80,80,frames_to_net))\n",
    "    future_frames = np.zeros((nframes,80,80,frames_to_net))\n",
    "  \n",
    "    if game >= warmupgames:\n",
    "        # choosing the frames from memory buffer based on the reward\n",
    "        # weighing the frames \n",
    "        # something like over/under sampling in unbalanced class\n",
    "        prob = np.ones(len_buff)\n",
    "        prob[np.array(buffer['rewards']) > 0] = 10.0\n",
    "        prob /= np.sum(prob)\n",
    "        which_choose = np.random.choice(len_buff,size=nframes,replace=False,p=prob)\n",
    "    \n",
    "        rewards = np.zeros(nframes)\n",
    "        actions = np.zeros(nframes)\n",
    "        for grab in range(nframes):\n",
    "            rewards[grab] = buffer['rewards'][which_choose[grab]]\n",
    "            actions[grab] = buffer['actions'][which_choose[grab]]\n",
    "            # creating frame - current t (for prediction) and t+1 (for truth)\n",
    "            current_frames[grab,:,:,:] = buffer['frames'][which_choose[grab]].copy()\n",
    "            current_frames[grab,:,:,:] = buffer['frames'][which_choose[grab] - 1].copy()\n",
    "            \n",
    "#             for f in range(frames_to_net):\n",
    "#                 if grab-f > 0:\n",
    "#                     current_frames[grab,:,:,f] = buffer['frames'][which_choose[grab]-f].copy()\n",
    "#                 if (grab-f+1 > 0) & (grab-f+1 < len_buff-1):\n",
    "#                     future_frames[grab,:,:,f] = buffer['frames'][which_choose[grab]-f+1].copy()\n",
    "\n",
    "\n",
    "    target_vf = mod.predict(future_frames)\n",
    "\n",
    "    # vectors of truth\n",
    "    y0 = np.zeros((nframes,1))\n",
    "    y1 = np.zeros((nframes,1))\n",
    "    y2 = np.zeros((nframes,1))\n",
    "    \n",
    "    # weight for training neural network based on the \"truth\"\n",
    "    weight0 = np.zeros(nframes)\n",
    "    weight1 = np.zeros(nframes)\n",
    "    weight2 = np.zeros(nframes)\n",
    "  \n",
    "\n",
    "    for grab in range(nframes):\n",
    "        rhs = rewards[grab]\n",
    "        # terminal condition will be when we win a game\n",
    "        # \n",
    "        if rhs == 0:\n",
    "            rhs = delt*np.max([target_vf[0][grab],target_vf[1][grab],target_vf[2][grab]])\n",
    "        if actions[grab] == 0:\n",
    "            y0[grab,0] = rhs\n",
    "            weight0[grab] = 1\n",
    "        elif actions[grab] == 1:\n",
    "            y1[grab,0] = rhs\n",
    "            weight1[grab] = 1\n",
    "        else:\n",
    "            y2[grab,0] = rhs\n",
    "            weight2[grab] = 1\n",
    "  \n",
    "    mod.fit(current_frames,[y0,y1,y2],epochs=1,batch_size=nbatch,verbose=0,sample_weight={'out0':weight0,'out1':weight1,'out2':weight2},use_multiprocessing=True)\n",
    "    stop = time.time()\n",
    "    # print([game, score, eps, stop-start])\n",
    "    \n",
    "    output_qdl['game'][game] = game\n",
    "    output_qdl['score'][game] = score\n",
    "    output_qdl['time'][game] = time\n",
    "    \n",
    "    if game % 10 == 0:\n",
    "        print('Game number ', game, [score, eps, stop-start])\n",
    "\n",
    "overall_end = time.time()\n",
    "print('total run time, ', (overall_end - overall_start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0008de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/dqlv2\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "mod.save('saved_model/dqlv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "036f3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([75.,  0.,  0.,  0.,  0., 20.,  0.,  0.,  0.,  5.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([x+21 for x in output_qdl['score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81562d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
