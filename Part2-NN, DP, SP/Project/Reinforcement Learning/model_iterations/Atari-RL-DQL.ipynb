{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f36990aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\lib\\site-packages\\ale_py\\roms\\__init__.py:94: DeprecationWarning: Automatic importing of atari-py roms won't be supported in future releases of ale-py. Please migrate over to using `ale-import-roms` OR an ALE-supported ROM package. To make this warning disappear you can run `ale-import-roms --import-from-pkg atari_py.atari_roms`.For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\n",
      "  _RESOLVED_ROMS = _resolve_roms()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99886234",
   "metadata": {},
   "source": [
    "## Pong\n",
    "\n",
    "Deep Q learning with memory buffer - varying probs to oversample minority (cases when you win), action every 4 frame, and linear annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e714c451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# function to convert each image into lesser size\n",
    "def prepro(I):\n",
    "    # preprocess each frame for learning\n",
    "    # save some memory and computation\n",
    "    # pre-process the image from a 210x160x3 uint8 frame into an (80x80) float array \n",
    "    I = I[35:195,:,:].copy() # crop the top of the image...score image doesn't matter for how to play\n",
    "    I = I[::2,::2,0].copy()\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return np.array(I.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9035db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(height,width,channels):\n",
    "    # we cannot simply have 3 output nodes because we want to put a weight on each node's impact to the objective\n",
    "    # that is different for each data point.  the only way to achieve this is to have 3 output layers, each having 1 node\n",
    "    # the effect is the same, just the way TF/keras handles weights is different\n",
    "    imp = Input(shape=(height,width,channels))\n",
    "    mid = Conv2D(32,(8,8),strides=4,activation='relu')(imp)\n",
    "    mid = Conv2D(64,(4,4),strides=2,activation='relu')(mid)\n",
    "    mid = Conv2D(64,(3,3),strides=1,activation='relu')(mid)\n",
    "    mid = Flatten()(mid)\n",
    "    mid = Dense(256,activation='relu')(mid)\n",
    "    out0 = Dense(1,activation='linear',name='out0')(mid)\n",
    "    out1 = Dense(1,activation='linear',name='out1')(mid)\n",
    "    out2 = Dense(1,activation='linear',name='out2')(mid)\n",
    "    model = Model(imp,[out0,out1,out2]) \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=25e-6),loss=tf.keras.losses.Huber())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ca19ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 80, 80, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 19, 19, 32)   8224        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 64)     32832       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 6, 64)     36928       ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2304)         0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          590080      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " out0 (Dense)                   (None, 1)            257         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " out1 (Dense)                   (None, 1)            257         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " out2 (Dense)                   (None, 1)            257         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 668,835\n",
      "Trainable params: 668,835\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frames_to_net = 4              # how many previous frames will we feed the NN\n",
    "possible_actions = [0,2,3]\n",
    "mod = create_model(80,80,frames_to_net)\n",
    "mod.call = tf.function(mod.call,experimental_relax_shapes=True)\n",
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc61e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play1game(model,ep):\n",
    "    env0 = gym.make(\"Pong-v0\")\n",
    "    pix = env0.reset()\n",
    "    pix = prepro(pix)\n",
    "    frames_this_game = 0\n",
    "    feed = np.zeros((1,80,80,frames_to_net))\n",
    "    feed[0,:,:,0] = pix.copy() # 0 is the most recent frame t; 1 the previous one t+1 and so one\n",
    "    \n",
    "    frame_array = []\n",
    "    action_array = []\n",
    "    reward_array = []\n",
    "    \n",
    "    score = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # updating action every 4 frames\n",
    "        # but taking that action for the 4 frames just not using the prediction for action\n",
    "        if frames_this_game % 4 == 0:\n",
    "            if np.random.random() < ep:\n",
    "                action = np.random.choice(3)\n",
    "            else:\n",
    "                vf = mod(feed,training=False)\n",
    "                vf = [vf[0][0,0].numpy(),vf[1][0,0].numpy(),vf[2][0,0].numpy()]\n",
    "                action = np.argmax(vf)\n",
    "        action0 = possible_actions[action]\n",
    "        pix_new, reward, done, info = env0.step(action0)\n",
    "        frame_array.append(pix)\n",
    "        action_array.append(action)\n",
    "        reward_array.append(reward)\n",
    "        pix = prepro(pix_new)\n",
    "        frames_this_game += 1\n",
    "\n",
    "        for f in range(1,frames_to_net):\n",
    "            feed[0,:,:,frames_to_net-f] = feed[0,:,:,frames_to_net-f-1].copy()\n",
    "        feed[0,:,:,0] = pix.copy()\n",
    "        score += reward\n",
    "    return frame_array, action_array, reward_array, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719f8cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25194401244167963 0.26127527216174184 0.4867807153965785\n"
     ]
    }
   ],
   "source": [
    "# testing the likelihood of taking each action without any training\n",
    "frames, actions, rewards, score = play1game(mod,0.5)\n",
    "print(np.mean(np.array(actions)==0),np.mean(np.array(actions)==1),np.mean(np.array(actions)==2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8723a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discounting factor\n",
    "delt = 0.99\n",
    "\n",
    "# setting up variable for memory buffer\n",
    "# ngames = 1000\n",
    "ngames = 100\n",
    "nbatch = 10\n",
    "buffn = 200000\n",
    "warmupgames = 50\n",
    "len_buff = 0\n",
    "buffer = {'frames':[],'actions':[], 'rewards':[]}\n",
    "\n",
    "# eps vector for each gradient for linear annealing\n",
    "epsvec = np.linspace(1,0.05,ngames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53c36f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game number  0 [-21.0, 1.0, 3.597517251968384]\n",
      "Game number  10 [-21.0, 0.9040404040404041, 4.0382843017578125]\n",
      "Game number  20 [-20.0, 0.8080808080808081, 5.42009973526001]\n",
      "Game number  30 [-21.0, 0.7121212121212122, 4.9214231967926025]\n",
      "Game number  40 [-21.0, 0.6161616161616161, 5.239348649978638]\n",
      "Game number  50 [-21.0, 0.5202020202020202, 5.495059967041016]\n",
      "Game number  60 [-21.0, 0.4242424242424243, 5.062440633773804]\n",
      "Game number  70 [-21.0, 0.3282828282828283, 5.357397556304932]\n",
      "Game number  80 [-20.0, 0.23232323232323238, 6.475332498550415]\n",
      "Game number  90 [-21.0, 0.13636363636363646, 6.127270698547363]\n",
      "total run time,  9.284054215749105 minutes\n"
     ]
    }
   ],
   "source": [
    "output_qdl = {'game':[-1]*ngames, 'score':[-100]*ngames, 'time':[-1]*ngames}\n",
    "\n",
    "overall_start = time.time()\n",
    "\n",
    "for game in range(ngames):\n",
    "    start = time.time()\n",
    "    frames, actions, rewards, score = play1game(mod,epsvec[game])\n",
    "    buffer['frames'] += frames.copy()\n",
    "    buffer['actions'] += actions.copy()\n",
    "    buffer['rewards'] += rewards.copy()\n",
    "    len_buff += len(actions)\n",
    "    if len_buff > buffn:\n",
    "        excess = len_buff - buffn\n",
    "        buffer['frames'] = buffer['frames'][excess:].copy()\n",
    "        buffer['actions'] = buffer['actions'][excess:].copy()\n",
    "        buffer['rewards'] = buffer['rewards'][excess:].copy()\n",
    "        len_buff = len(buffer['actions'])\n",
    "    \n",
    "    # rewards = np.array(rewards)\n",
    "    # actions = np.array(actions)\n",
    "    \n",
    "    nframes = len(frames)\n",
    "    current_frames = np.zeros((nframes,80,80,frames_to_net))\n",
    "    future_frames = np.zeros((nframes,80,80,frames_to_net))\n",
    "  \n",
    "    if game >= warmupgames:\n",
    "        # choosing the frames from memory buffer based on the reward\n",
    "        # weighing the frames \n",
    "        # something like over/under sampling in unbalanced class\n",
    "        prob = np.ones(len_buff)\n",
    "        prob[np.array(buffer['rewards']) > 0] = 5.0\n",
    "        prob /= np.sum(prob)\n",
    "        which_choose = np.random.choice(len_buff,size=nframes,replace=False,p=prob)\n",
    "    \n",
    "        rewards = np.zeros(nframes)\n",
    "        actions = np.zeros(nframes)\n",
    "        for i in range(len(which_choose)):\n",
    "            grab = which_choose[i]\n",
    "            rewards[i] = buffer['rewards'][grab]\n",
    "            actions[i] = buffer['actions'][grab]\n",
    "            # creating frame - current t (for prediction) and t+1 (for truth)\n",
    "            for f in range(frames_to_net):\n",
    "                if grab-f > 0:\n",
    "                    current_frames[i,:,:,f] = buffer['frames'][grab-f].copy()\n",
    "                if (grab-f+1 > 0) & (grab-f+1 < len_buff-1):\n",
    "                    future_frames[i,:,:,f] = buffer['frames'][grab-f+1].copy()\n",
    "\n",
    "\n",
    "    target_vf = mod.predict(future_frames)\n",
    "\n",
    "    # vectors of truth\n",
    "    y0 = np.zeros((nframes,1))\n",
    "    y1 = np.zeros((nframes,1))\n",
    "    y2 = np.zeros((nframes,1))\n",
    "    \n",
    "    # weight for training neural network based on the \"truth\"\n",
    "    weight0 = np.zeros(nframes)\n",
    "    weight1 = np.zeros(nframes)\n",
    "    weight2 = np.zeros(nframes)\n",
    "  \n",
    "\n",
    "    for grab in range(nframes):\n",
    "        rhs = rewards[grab]\n",
    "        # terminal condition will be when we win a game\n",
    "        # \n",
    "        if rhs == 0:\n",
    "            rhs = delt*np.max([target_vf[0][grab],target_vf[1][grab],target_vf[2][grab]])\n",
    "        if actions[grab] == 0:\n",
    "            y0[grab,0] = rhs\n",
    "            weight0[grab] = 1\n",
    "        elif actions[grab] == 1:\n",
    "            y1[grab,0] = rhs\n",
    "            weight1[grab] = 1\n",
    "        else:\n",
    "            y2[grab,0] = rhs\n",
    "            weight2[grab] = 1\n",
    "  \n",
    "    mod.fit(current_frames,[y0,y1,y2],epochs=1,batch_size=nbatch,verbose=0,sample_weight={'out0':weight0,'out1':weight1,'out2':weight2},use_multiprocessing=True)\n",
    "    stop = time.time()\n",
    "    # print([game, score, epsvec[game], stop-start])\n",
    "    \n",
    "    output_qdl['game'][game] = game\n",
    "    output_qdl['score'][game] = score\n",
    "    output_qdl['time'][game] = time\n",
    "    \n",
    "    if game % 10 == 0:\n",
    "        print('Game number ', game, [score, epsvec[game], stop-start])\n",
    "\n",
    "overall_end = time.time()\n",
    "print('total run time, ', (overall_end - overall_start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0008de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/dql\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "mod.save('saved_model/dql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "036f3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([75.,  0.,  0.,  0.,  0., 20.,  0.,  0.,  0.,  5.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist([x+21 for x in output_qdl['score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81562d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
